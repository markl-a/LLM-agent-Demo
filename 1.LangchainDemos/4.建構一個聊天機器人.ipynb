{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUrF_aox7Oug"
      },
      "source": [
        "# 建構一個 Chatbot:\n",
        "\n",
        "此範例是根據[這個](https://python.langchain.com/v0.2/docs/tutorials/chatbot/)改編\n",
        "\n",
        "我們將透過一個範例來說明如何設計和實現由LLM支援的Chatbot。該Chatbot將能夠進行對話並記住先前的互動。\n",
        "\n",
        "請注意，我們建立的這個Chatbot將僅使用語言模型進行對話。您可能正在尋找其他幾個相關概念：\n",
        "\n",
        "- [會話式 RAG](https://python.langchain.com/v0.2/docs/tutorials/qa_chat_history/)：透過外部資料來源實現Chatbot體驗。\n",
        "\n",
        "- [Agent](https://python.langchain.com/v0.2/docs/tutorials/agents/)：建構一個可以採取行動的Chatbot。\n",
        "\n",
        "本教程將涵蓋對這兩個更高級主題有幫助的基礎知識，但如果您選擇，可以直接跳到那裡。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbX63zi6Kt8x",
        "outputId": "19a41155-2520-40d6-b86f-4b95fdb877ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.14)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.32 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.33)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.99)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain) (3.0.0)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.4/362.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install -qU langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z2Bvp8g71PV"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "# 替換為你的LANGCHAIN_API_KEY\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"替換為你的LANGCHAIN_API_KEY\"\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"替換為你的OPENAI_API_KEY\"\n",
        "\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3fIdfGT8q-Z",
        "outputId": "45368c65-5e08-4d65-a100-34f5c89b7e2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='你好飛魚，很高興能和你聊天。有什麼可以幫助你的嗎？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 17, 'total_tokens': 54}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-971d220b-7ed4-4c25-93c6-7203501457d1-0', usage_metadata={'input_tokens': 17, 'output_tokens': 37, 'total_tokens': 54})"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "model.invoke([HumanMessage(content=\"你好 我是飛魚\")])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzhl8Udd_JE6"
      },
      "source": [
        "API 參考：[HumanMessage](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.human.HumanMessage.html)\n",
        "該模型本身沒有任何狀態概念。例如，如果您提出後續問題：\n",
        "model.invoke([HumanMessage(content=\"叫我的名字？\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixc1GUx0CYx7",
        "outputId": "eed562b8-6c22-4d47-cc55-3eae545cdf10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='抱歉，我无法知道你的名字，因为我是一个虚拟助手。您可以告诉我您的名字，我们可以继续交流。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 13, 'total_tokens': 61}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7170be91-6477-4c0a-8d55-729b6ce88943-0', usage_metadata={'input_tokens': 13, 'output_tokens': 48, 'total_tokens': 61})"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.invoke([HumanMessage(content=\"我叫啥?\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz16FjZ-blZ1"
      },
      "source": [
        "可以看出，它沒有將前面的對話轉入上下文，無法回答問題。這會帶來糟糕的聊天機器人體驗！\n",
        "\n",
        "為了解決這個問題，我們需要將整個對話歷史記錄傳遞到模型中。讓我們看看這樣做時會發生什麼：\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUDQPJ81cVkn",
        "outputId": "03203b85-15fe-4dc3-89ab-8a791472a6a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Your name is Bob. How can I assist you today, Bob?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 35, 'total_tokens': 49}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8c5dca86-adaf-4bc9-8b62-1990c682f667-0', usage_metadata={'input_tokens': 35, 'output_tokens': 14, 'total_tokens': 49})"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import AIMessage\n",
        "\n",
        "model.invoke(\n",
        "    [\n",
        "        HumanMessage(content=\"Hi! I'm Bob\"),\n",
        "        AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
        "        HumanMessage(content=\"What's my name?\"),\n",
        "    ]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x7f3rcJc_s8"
      },
      "source": [
        "上方為官方的教學，現在我們可以看到我們從GPT那得到還可以的回應！\n",
        "\n",
        "這就是聊天機器人對話互動能力的基本想法。\n",
        "\n",
        "不過假如改成中文會有怎樣的效果，效果如下："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mFm_FaDbm5B",
        "outputId": "e13b752e-65b6-4576-8aa0-4e610590f389"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='抱歉，我不知道你的名字。你可以告訴我你的名字嗎？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 67, 'total_tokens': 95}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f734f6d1-ad04-4ffa-8b2a-82365cd96580-0', usage_metadata={'input_tokens': 67, 'output_tokens': 28, 'total_tokens': 95})"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import AIMessage\n",
        "\n",
        "model.invoke(\n",
        "    [\n",
        "        HumanMessage(content=\"你好 我是飛魚\"),\n",
        "        AIMessage(content=\"你好飛魚，很高興能和你聊天。有什麼可以幫助你的嗎？\"),\n",
        "        HumanMessage(content=\"我的名字是?\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtJzhvlycxwg",
        "outputId": "5425bafd-f047-4175-9cb3-bc2f2637f76c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='您剛才說您的名字叫飛魚。您想要我們用另一個名字來稱呼您嗎？', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 71, 'total_tokens': 116}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a417d8a3-9f3c-4133-9da7-601ebef41f7b-0', usage_metadata={'input_tokens': 71, 'output_tokens': 45, 'total_tokens': 116})"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import AIMessage\n",
        "\n",
        "model.invoke(\n",
        "    [\n",
        "        HumanMessage(content=\"你好 我的名字叫飛魚\"),\n",
        "        AIMessage(content=\"你好飛魚，很高興能和你聊天。有什麼可以幫助你的嗎？\"),\n",
        "        HumanMessage(content=\"我的名字是?\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VswnSoiceS2"
      },
      "source": [
        "從上面可以看到，在繁體中文方面可能因為沒有那麼多的資料，又或者因為沒有那麼多的微調或RLHF，所以必須寫得特別直接才有正確的回應，不過這只是GPT 3.5的情況，或許這會在GPT4或之後的版本就改善了。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JScg5obheG03"
      },
      "source": [
        "# 歷史訊息\n",
        "\n",
        "我們可以使用訊息歷史記錄類別來包裝我們的模型並使其具有狀態。這可用於追蹤模型的輸入和輸出，並將它們儲存在某個資料儲存中。未來的互動將載入這些訊息並將它們作為輸入的一部分傳遞到運作中。讓我們看看如何使用它！\n",
        "\n",
        "首先，讓我們確保安裝langchain-community，因為我們將使用其中的整合來儲存訊息歷史記錄。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm77Ma4Gd-_c",
        "outputId": "a7a6b47a-6fc2-4607-a376-1ccf84d5d83d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.13 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.14)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.30 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.99)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (2.20.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.2.12-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain_community-0.2.12 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "! pip install langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NSPXa7BeYhS"
      },
      "outputs": [],
      "source": [
        "from langchain_core.chat_history import (\n",
        "    BaseChatMessageHistory,\n",
        "    InMemoryChatMessageHistory,\n",
        ")\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "store = {}\n",
        "\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = InMemoryChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "\n",
        "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvHP4yrjeghx"
      },
      "source": [
        "API 參考：[BaseChatMessageHistory](https://api.python.langchain.com/en/latest/chat_history/langchain_core.chat_history.BaseChatMessageHistory.html) |[記憶體中聊天訊息歷史記錄](https://api.python.langchain.com/en/latest/chat_history/langchain_core.chat_history.InMemoryChatMessageHistory.html)| [RunnableWithMessageHistory](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html)\n",
        "\n",
        "\n",
        "我們現在需要建立一個 `config`  每次傳遞到可運行物件中的物件。此配置包含的資訊不是直接輸入的一部分，但仍然有用。在本例子中，我們需要包含一個 `session_id` .這應該看起來像："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "o5ZzydqGgEpj",
        "outputId": "b1051d47-602b-42b2-f670-3021d1c5e47c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Your name is Bob. How can I help you today, Bob?'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config = {\"configurable\": {\"session_id\": \"abc1\"}}\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"Hi! I'm Bob\")],\n",
        "    config=config,\n",
        ")\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"What's my name?\")],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hlBi0RtHe1v1",
        "outputId": "aed432c4-2501-4e11-c19d-f70169d87371"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'非常抱歉，我无法得知您的真实姓名。如果您有其他问题或需要帮助，请随时告诉我。我会尽力提供支持。'"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config = {\"configurable\": {\"session_id\": \"abc2\"}}\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"你好 我的名字是取把勾\")],\n",
        "    config=config,\n",
        ")\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"我的名字是? \")],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "m5UuYWLBfgLd",
        "outputId": "981ee425-fa86-489a-fa8e-78251faa82c7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'抱歉，我无法直接获取你的名字。请问有什么问题或者需要帮助的吗？'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ChatOpenAI(model=\"gpt-4o\")\n",
        "config = {\"configurable\": {\"session_id\": \"abc3\"}}\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"你好 我的名字是取把勾\")],\n",
        "    config=config,\n",
        ")\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"我的名字是? \")],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqcCMsB7hWAQ"
      },
      "source": [
        "看來這方面就算改成 gpt-4o的模型也沒有改變。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XkiS0TsyhdTc",
        "outputId": "9c73aa7b-c3b8-4149-adff-86974bf7cc1a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I'm sorry, I don't have access to personal information like your name. How can I assist you today?\""
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "config = {\"configurable\": {\"session_id\": \"abc3\"}}\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"What's my name?\")],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYqX4daAjnoP"
      },
      "source": [
        "然而，我們是可以回到原來的對話（因為其對話保存在資料庫中）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J34mBxNijvW6",
        "outputId": "8a22d976-1dbb-411f-fe7d-e100bd8331e0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Your name is Bob. How can I assist you, Bob?'"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config = {\"configurable\": {\"session_id\": \"abc1\"}}\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"What's my name?\")],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ym6v4RMejxUS",
        "outputId": "416a004f-adaa-43eb-afdd-376b164a5264"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I'm sorry, I don't have access to personal information such as your name. If you would like to share your name with me, feel free to do so. How can I assist you today?\""
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config = {\"configurable\": {\"session_id\": \"abc2\"}}\n",
        "\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"What's my name?\")],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsFNMqAKj_8f"
      },
      "source": [
        "如此一來，我們便能讓聊天機器人同時與多位用戶暢談！(看來只能用英文)\n",
        "\n",
        "目前，我們只是在模型周圍添加了一個簡單的持久層(存儲對話)。接下來，我們可以引入提示模板，使對話變得更加複雜和個性化。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35d8DIyDkmcy"
      },
      "source": [
        "# 提示模板\n",
        "\n",
        "提示模板有助於將原始用戶資訊轉換為LLM可處理的格式。在當前情境中，原始用戶輸入僅僅是一條訊息，我們將其直接傳遞給LLM。現在，讓我們稍微複雜化一點。首先，讓我們添加一條包含自定義指令的系統訊息（但仍將訊息作為輸入）。接下來，我們將添加更多輸入，而不僅僅是訊息。\n",
        "\n",
        "首先，讓我們添加一條系統訊息。為此，我們將創建一個 `ChatPromptTemplate`。我們將利用 `MessagesPlaceholder` 來傳遞所有訊息。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yG6c9QW6j4DU",
        "outputId": "a8e4236c-65b3-40b8-ab49-e967685cb5ee"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hello Bob! How can I assist you today?'"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | model\n",
        "\n",
        "response = chain.invoke({\"messages\": [HumanMessage(content=\"hi! I'm bob\")]})\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BbBEZ_NKlZAv",
        "outputId": "b85cb188-2975-41ac-be2b-28c5a9b0fd14"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'你好! 有什麼問題我可以幫忙解答嗎？'"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | model\n",
        "\n",
        "response = chain.invoke({\"messages\": [HumanMessage(content=\"你好! 我是飛魚\")]})\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap1Slsmyl4TT"
      },
      "source": [
        "API 參考：[ChatPromptTemplate](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html) | [MessagesPlaceholder](https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.MessagesPlaceholder.html)\n",
        "\n",
        "請注意，這稍微改變了輸入類型 - 現在我們不再傳入一個訊息列表，而是傳入一個字典，其中包含一個 `messages` 鍵，該鍵的值是一個訊息列表。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyjXwydLmU33"
      },
      "source": [
        "現在，我們可以像之前一樣，將其封裝在 Messages History 對象中。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VpOC5w1Rlpix",
        "outputId": "298688fe-ae84-4e44-ede4-b0f06e3f2536"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hello Jim! How can I assist you today?'"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with_message_history = RunnableWithMessageHistory(chain, get_session_history)\n",
        "config = {\"configurable\": {\"session_id\": \"abc5\"}}\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"Hi! I'm Jim\")],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "S5YBj7EmmZpg",
        "outputId": "23276cac-8343-4e9c-c61d-ed916544156f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Your name is Jim.'"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"What's my name?\")],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_taR-BZjndIU"
      },
      "source": [
        "不過繁中方面感覺還是沒微調過"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "g1y3AoAFmiBd",
        "outputId": "287d9e39-7116-4847-d309-51dcc906df83"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'你好，阿拉丁！有什么可以帮助你的吗？'"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "with_message_history = RunnableWithMessageHistory(chain, get_session_history)\n",
        "config = {\"configurable\": {\"session_id\": \"abc6\"}}\n",
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"你好！我是阿拉丁\")],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_Tlhd2cjnNDb",
        "outputId": "50fd6d28-1f61-43c7-873b-70c61a957103"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'抱歉，我无法猜测你是谁。您可以告诉我更多关于您的信息吗？我会尽力帮助您。'"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = with_message_history.invoke(\n",
        "    [HumanMessage(content=\"你猜猜我是?\")],\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GyTpHjynqB1"
      },
      "source": [
        "現在讓我們來讓提示模板變得更為複雜一點。假設提示模板現在看起來像這樣：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DYR44UiInRvp",
        "outputId": "90007d37-c9a3-45a8-95b3-6c61c4fd24a3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'¡Hola, Bob! ¿En qué puedo ayudarte hoy?'"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | model\n",
        "\n",
        "response = chain.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"hi! I'm bob\")], \"language\": \"Spanish\"}\n",
        ")\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IROErv_En9tN"
      },
      "source": [
        "請注意，我們在提示中新增了一個 `language` 輸入。現在，我們可以調用 chain並傳入我們選擇的語言。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-uK5N7AHn-fO",
        "outputId": "92500713-468c-4c30-b4b6-169079bc346d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'¡Hola Mark! ¿En qué puedo ayudarte hoy?'"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | model\n",
        "\n",
        "response = chain.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"你好！我是馬克\")], \"language\": \"Spanish\"}\n",
        ")\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68_W-lujojWD"
      },
      "source": [
        "看來這個有微調過，或是有相關的資料集訓練過。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "230gPHQaoiBr"
      },
      "source": [
        "讓我們將這個更複雜的鏈封裝在 `Message History` 類中。這次，由於輸入中有多個鍵，我們需要指定正確的鍵來保存聊天歷史記錄。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "808TlPu7nzA-",
        "outputId": "9ac68d4f-8062-47c6-9ab0-beb4e513af9a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'¡Hola Todd! ¿En qué puedo ayudarte hoy?'"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with_message_history = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"messages\",\n",
        ")\n",
        "config = {\"configurable\": {\"session_id\": \"abc11\"}}\n",
        "response = with_message_history.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"hi! I'm todd\")], \"language\": \"Spanish\"},\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "A9ATVthdo28u",
        "outputId": "63518e6e-a375-49f1-9831-4179b741f5cd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tu nombre es Todd. ¿Hay algo más en lo que pueda ayudarte?'"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = with_message_history.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"whats my name?\")], \"language\": \"Spanish\"},\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0cKMI_k6o3lE",
        "outputId": "dc459524-ff08-403e-fd29-20c3a6d01f2d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'¡Hola! ¿En qué puedo ayudarte hoy?'"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with_message_history = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"messages\",\n",
        ")\n",
        "config = {\"configurable\": {\"session_id\": \"abc12\"}}\n",
        "response = with_message_history.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"你好！我是阿桃\")], \"language\": \"Spanish\"},\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nqGM88jbpGPH",
        "outputId": "d1631b70-ba95-43e3-c4b5-2054af213c64"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tu nombre es \"阿桃\"。 ¿Hay algo más en lo que pueda ayudarte?'"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = with_message_history.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"我叫啥?\")], \"language\": \"Spanish\"},\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNY1E_hBpPH_"
      },
      "source": [
        "這個中文是回答正確的，很神奇就是，可能是封裝的類裡面有設定相關的prompt，或者之前的系統prompt 有產生作用。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Eml_UM1qbDI"
      },
      "source": [
        "## 管理對話歷史\n",
        "\n",
        "在構建聊天機器人時，一個重要的概念是要理解如何管理對話歷史。如果不加以管理，訊息列表會無限增長，可能超出 LLM 的上下文窗口。因此，添加一個步驟來限制傳入訊息的大小非常重要。\n",
        "\n",
        "重要的是，您需要在**提示模板之前**執行此操作，但在**從訊息歷史記錄載入先前的訊息之後**執行。\n",
        "\n",
        "我們可以在提示前添加一個簡單的步驟，以適當地修改 `messages` 鍵，然後將這個新的鏈封裝在 `Message History` 類中。\n",
        "\n",
        "LangChain 提供了一些內建的輔助工具來**管理訊息列表( [managing a list of messages](https://python.langchain.com/v0.2/docs/how_to/#messages))**。在這種情況下，我們將使用  [trim_messages](https://python.langchain.com/v0.2/docs/how_to/trim_messages/)  輔助工具來減少我們發送到模型的訊息數量。此修剪器允許我們指定要保留多少個 token，以及其他參數，例如是否始終保留系統訊息以及是否允許部分訊息。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZF1-jG9psSi",
        "outputId": "89ad2b8e-f252-4b70-a54f-b045fdbba755"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessage(content=\"you're a good assistant\"),\n",
              " HumanMessage(content='whats 2 + 2'),\n",
              " AIMessage(content='4'),\n",
              " HumanMessage(content='thanks'),\n",
              " AIMessage(content='no problem!'),\n",
              " HumanMessage(content='having fun?'),\n",
              " AIMessage(content='yes!')]"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import SystemMessage, trim_messages\n",
        "\n",
        "trimmer = trim_messages(\n",
        "    max_tokens=65,\n",
        "    strategy=\"last\",\n",
        "    token_counter=model,\n",
        "    include_system=True,\n",
        "    allow_partial=False,\n",
        "    start_on=\"human\",\n",
        ")\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"you're a good assistant\"),\n",
        "    HumanMessage(content=\"hi! I'm bob\"),\n",
        "    AIMessage(content=\"hi!\"),\n",
        "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
        "    AIMessage(content=\"nice\"),\n",
        "    HumanMessage(content=\"whats 2 + 2\"),\n",
        "    AIMessage(content=\"4\"),\n",
        "    HumanMessage(content=\"thanks\"),\n",
        "    AIMessage(content=\"no problem!\"),\n",
        "    HumanMessage(content=\"having fun?\"),\n",
        "    AIMessage(content=\"yes!\"),\n",
        "]\n",
        "\n",
        "trimmer.invoke(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TQiXsejq--d"
      },
      "source": [
        "API [Reference:SystemMessage](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.system.SystemMessage.html) | [trim_messages](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.utils.trim_messages.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NfcPdaOrHb2"
      },
      "source": [
        "要在我們的 chain 中使用它，我們只需要在將 `messages` 輸入傳遞給提示模板之前執行修剪器。\n",
        "\n",
        "現在，如果我們嘗試詢問模型我們的名字，它將無法回答，因為我們修剪了聊天歷史記錄中的那一部分。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ij3gSugnrRTX",
        "outputId": "e4fa48e0-48f3-4cb5-b20d-b920ca9961b5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I'm sorry, I don't have access to your name. How can I assist you today?\""
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "chain = (\n",
        "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer)\n",
        "    | prompt\n",
        "    | model\n",
        ")\n",
        "\n",
        "response = chain.invoke(\n",
        "    {\n",
        "        \"messages\": messages + [HumanMessage(content=\"what's my name?\")],\n",
        "        \"language\": \"English\",\n",
        "    }\n",
        ")\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDIIRCH5rZIr"
      },
      "source": [
        "API Reference: [RunnablePassthrough](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.passthrough.RunnablePassthrough.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOExxdcdrqnb"
      },
      "source": [
        "但如果我們詢問有關過去幾條消息中的資訊，它會記得：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kvqVVQw8rdzH",
        "outputId": "e54d3c03-2841-41ef-ffc1-da570682b291"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'You asked \"what\\'s 2 + 2?\"'"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = chain.invoke(\n",
        "    {\n",
        "        \"messages\": messages + [HumanMessage(content=\"what math problem did i ask\")],\n",
        "        \"language\": \"English\",\n",
        "    }\n",
        ")\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-dNCuIGr21M"
      },
      "source": [
        "現在，讓我們將其封裝在 Message History 中。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QR3awbB2rsqR",
        "outputId": "dd611be9-4747-4526-ea63-76e2b7b6b3c8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I'm sorry, I don't know your name.\""
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with_message_history = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"messages\",\n",
        ")\n",
        "\n",
        "config = {\"configurable\": {\"session_id\": \"abc20\"}}\n",
        "response = with_message_history.invoke(\n",
        "    {\n",
        "        \"messages\": messages + [HumanMessage(content=\"whats my name?\")],\n",
        "        \"language\": \"English\",\n",
        "    },\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxQIq9jNsVJ0"
      },
      "source": [
        "如預期的那樣，我們一開始提到名字的第一條消息已被修剪掉了。此外，聊天歷史記錄中現在多了兩條新消息（我們最新的問題和最新的回應）。這意味著之前在我們的對話歷史中可訪問的更多資訊現在不再可用！在這種情況下，我們最初的數學問題也已從歷史記錄中修剪掉，因此模型不再知道它了：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qA64CHOPsLJG",
        "outputId": "c96a487c-1836-41bf-9696-741f1f7d8868"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"You haven't asked me a math problem yet. Feel free to ask, and I'll do my best to help you with it.\""
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = with_message_history.invoke(\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"what math problem did i ask?\")],\n",
        "        \"language\": \"English\",\n",
        "    },\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4UytXxYtbES"
      },
      "source": [
        "## 串流傳輸\n",
        "\n",
        "現在，我們已經有一個功能性的聊天機器人。然而，對於聊天機器人應用來說，一個非常重要的用戶體驗考量是串流傳輸。大型語言模型 (LLMs) 有時可能需要一段時間才能回應，因此為了改善用戶體驗，大多數應用程序會在每個 token 生成時就將其串流傳輸回來。這允許用戶看到進度。\n",
        "\n",
        "實際上，這樣做非常簡單！\n",
        "\n",
        "所有 chain 都公開了一個 `.stream` 方法，使用訊息歷史記錄的鏈也不例外。我們只需使用該方法來獲得串流回應即可。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo3-iv4hsZOq",
        "outputId": "e7f71114-3aa6-4019-8585-9c10c1e00fc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|Sure|,| Todd|!| Here|'s| a| joke| for| you|:| Why| did| the| scare|crow| win| an| award|?| Because| he| was| outstanding| in| his| field|!| 😄||"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"session_id\": \"abc15\"}}\n",
        "for r in with_message_history.stream(\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"hi! I'm todd. tell me a joke\")],\n",
        "        \"language\": \"English\",\n",
        "    },\n",
        "    config=config,\n",
        "):\n",
        "    print(r.content, end=\"|\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snCpvyG7tyyQ"
      },
      "source": [
        "後續步驟\n",
        "既然您已經了解了在 LangChain 中創建聊天機器人的基礎知識，接下來您可能會對一些進階教程感興趣：\n",
        "\n",
        "對話式 RAG： 使聊天機器人能夠與外部資料源進行交互。\n",
        "代理： 構建一個可以採取行動的聊天機器人。\n",
        "如果您想深入了解具體細節，以下是一些值得關注的內容：\n",
        "\n",
        "串流傳輸： 串流傳輸對於聊天應用至關重要。\n",
        "如何添加訊息歷史記錄： 深入了解與訊息歷史記錄相關的所有內容。\n",
        "如何管理大型訊息歷史記錄： 更多管理大型聊天歷史記錄的技術。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lzhTqy8vEFj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
